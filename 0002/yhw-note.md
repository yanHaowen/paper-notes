读书笔记：
开篇：大概介绍了最临近协同过滤算法的优点缺点。
缺点：对数据噪音和稀疏度不能很好处理，有冷启动问题(是什么?)，扩展度低(在哪个的拓展度)
优点：解决了传统临近算法的缺点(哪些缺点？)，也保证了比较正确率(怎样保证的？)

提出目标：怎样使用少量数据去预测大量人群的喜好，理解使用潜在的独立、不相关的数据集去生成推荐，
分析是否能使用专业的评论很好的预测普遍行为，讨论如何避免传统的陷阱在cf中

数据收集中，采用了爬取网络评论方式得到数据，使用百分之50的电影数代表了所有电影。因为大多数评级太低而去除，
最后剩下少量符合标准的数据。

数据分析：为了比较专家数据和普遍数据的好坏。
用了CDF图（概率分布图），该图的函数是F(x)=P(X<=x)
图1：每部电影的用户、专家评论数   每个人的评论的电影数
结论：每部电影至少有一个专家评论，且评论数不会超过100.而用户评论数在0-10000不等
每个专家至少评论400个电影，而有的用户没有评论过电影。且评论超过400部电影的用户只有百分之10
专家的系数系数更低

图2：每部电影的平均评级，每个用户给出的的平均评级（评论的总分数/评论的总电影数）
结论：用户对每部电影的平均给分较为集中，百分之10的电影低于0.45,百分之10的大于0.6.而专家对电影平均分比较分散，百分之10低于0.4,百分之10高于0.8
一般用户评分波动较大，而专家波动较小。这说明一般用户容易根据偏好来对电影做评价，而专家更加客观

图三：每部电影的评分标准误差，每个人的评分标准误差（对误差的理解是 所给评分较平均值的波动程度）
结论：专家误差范围比较分散在0-0.35。而用户的误差最低都是0.2。
对于每个用户，专家评级波动小，而用户的评级波动大。

分析结果：专家集和普通用户集大有不同。专家集更加的稀疏，专家的评级范围更大（不止限于某一类）。他们对
好的电影都持几乎相同的意见。他们的评级偏离更少。

最临近算法。采用的knn算法。距离取值用的是余弦相似度。但是它应该属于余弦相似度的一个变形，因为考虑到
用户的共同部分，于是加入了调整因子。
为了更好的预测，我们规定，我们要找出相似度大于δ的值(sim)，但是由于这个值会带来一些患处
如果这些电影没有当前评论（指的是没有专家的当前评论），那么调整因子都为0,没有一个sim值会超过阈值。
为了解决这个问题，我们又加入了一个τ作为确信阈值。确保经过δ筛选过后的专家集合仍然要大于此值。
如果小于了τ那么返回用户的均值。如果大于该值，会应用一个公式计算预测该用户对电影的评级。
预测出的评级可能会作为一个标准，看出用户的喜好，用于给用户推荐相关的电影。


预测推荐的错误率
当用专家平均值作为最差预测情况的时候，我们v把它叫做批判者的选择，这种时候MAE(平均绝对误差)高，覆盖率极高（100）
当使用τ= 10 andδ= 0.01, MAE明显下降而覆盖率略低
图5:当τ一定时候，MAE和δ成反比关系。τ一定，覆盖率随δ增大而减小。τ增加MAE先减后增
专家集在计算预测性较高的用户时准确性会降低

Top-N推荐的精确度
我对topN理解是，在计算出相似度后找到test集中与该相似度临近的人群。并通过这些计算出预测的电影评分，对于评级大于可推荐阈值(σ)的电影进行推荐
对于愿意接受任何高于平均项目的推荐的用户(2.5-3的评级)，基于专家的方法似乎表现得与标准NN-CF一样好。
